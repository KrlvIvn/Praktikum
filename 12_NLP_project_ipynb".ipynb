{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "12_NLP_project.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "999dc20a1b164bc3b6cd78cbe6600d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_529140cbd8ca4ab1966662a87795fece",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd2bcd56a0b7425ca32c91b1c7217520",
              "IPY_MODEL_09660d177d6646f79c247b5bd593dc70"
            ]
          }
        },
        "529140cbd8ca4ab1966662a87795fece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd2bcd56a0b7425ca32c91b1c7217520": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dba392717624413daa92643cb3beb98f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6097c0bdd0894b738b1df0b0085cddec"
          }
        },
        "09660d177d6646f79c247b5bd593dc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_429c4ee4e0df4c729fe1aaa0c1b19c51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [08:29&lt;00:00, 101.92s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71516623cf6a40358e896ded7c44485b"
          }
        },
        "dba392717624413daa92643cb3beb98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6097c0bdd0894b738b1df0b0085cddec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "429c4ee4e0df4c729fe1aaa0c1b19c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71516623cf6a40358e896ded7c44485b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KrlvIvn/Praktikum/blob/main/12_NLP_project_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyhB4lG81vnd"
      },
      "source": [
        "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
        "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNN7wyTN1zdW"
      },
      "source": [
        "# Проект для «Викишоп»"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT2N7X-k2FcI"
      },
      "source": [
        "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
        "\n",
        "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
        "\n",
        "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
        "\n",
        "**Инструкция по выполнению проекта**\n",
        "\n",
        "1. Загрузите и подготовьте данные.\n",
        "2. Обучите разные модели. \n",
        "3. Сделайте выводы.\n",
        "\n",
        "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
        "\n",
        "**Описание данных**\n",
        "\n",
        "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZk7f5bugjjP"
      },
      "source": [
        "**Комментарий студента:**\n",
        "- проект выполнен на Google Colab;  \n",
        "- ориентировочное время выполнение 20 минут."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCPzrLU02HJP"
      },
      "source": [
        "## Подготовка\n",
        "Работа выполнена в Google Colab (TPU).  \n",
        "Установка библиотеки transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSL8Zo292Tu6",
        "outputId": "57854987-f3c9-4a71-99b6-d8e9a13c1539"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cENC23SFRNU",
        "outputId": "0edcacda-7cea-4633-fc89-a33da789fa7a"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, \n",
            "and then re-execute this cell.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNSDyMFXw6A3"
      },
      "source": [
        "Импорт необходимых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvFvBLJV0Dkv"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score,make_scorer\n",
        " \n",
        "import torch\n",
        "import transformers as ppb\n",
        "from tqdm import notebook\n",
        " \n",
        "import nltk\n",
        "from nltk.corpus import stopwords as nltk_stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.dummy import DummyClassifier\n",
        " \n",
        " \n",
        "nltk.download('wordnet','stopwords','punkt','averaged_perceptron_tagger')\n",
        "from nltk.corpus import wordnet\n",
        " \n",
        " \n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQ-42fh0hjsF"
      },
      "source": [
        "## Импорт данных\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyoj29J24hPX"
      },
      "source": [
        "try:\n",
        "    comments = pd.read_csv('/datasets/toxic_comments.csv')\n",
        "except:\n",
        "    comments = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "8SBfrLRF2xJm",
        "outputId": "8da7fe03-3fa5-4203-ed45-c5196de0b060"
      },
      "source": [
        "comments.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  toxic\n",
              "0  Explanation\\nWhy the edits made under my usern...      0\n",
              "1  D'aww! He matches this background colour I'm s...      0\n",
              "2  Hey man, I'm really not trying to edit war. It...      0\n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
              "4  You, sir, are my hero. Any chance you remember...      0\n",
              "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
              "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
              "7  Your vandalism to the Matt Shirvington article...      0\n",
              "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
              "9  alignment on this subject and which are contra...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XY0eVdl241-"
      },
      "source": [
        "Преимущественно не токсичные комментарии соотношение 89,8% к 10,2% "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1zp5X-622Wu",
        "outputId": "eb3de3b3-6083-4735-e6fa-8fab34d3dbc8"
      },
      "source": [
        "comments.toxic.value_counts()/comments.shape[0]*100 #.plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    89.832112\n",
              "1    10.167888\n",
              "Name: toxic, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUq5guhB213b"
      },
      "source": [
        "def df_info(df):\n",
        "    '''\n",
        "  функция дает общее представление о датасете\n",
        "  \n",
        "  '''  \n",
        "    #print(80*\"+\")\n",
        "    df.info()\n",
        "    print(80*\"+\")\n",
        "    print(f'количество пропусков по столбцам:')\n",
        "    for i,j in enumerate(df.columns):\n",
        "      print(j,'=',df.iloc[:,i].isnull().sum())\n",
        "    print('Описание количественных переменных:')\n",
        "    print(df.describe(percentiles=[.25,.5]))\n",
        "    print(80*\"+\")\n",
        "    print(f'количество дубликатов в таблице = {df.duplicated().sum()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ2WI6_h3HlY",
        "outputId": "4c263f5c-2a41-430b-f1b8-47f19da9506f"
      },
      "source": [
        "df_info(comments)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 159571 entries, 0 to 159570\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    159571 non-null  object\n",
            " 1   toxic   159571 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 2.4+ MB\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "количество пропусков по столбцам:\n",
            "text = 0\n",
            "toxic = 0\n",
            "Описание количественных переменных:\n",
            "               toxic\n",
            "count  159571.000000\n",
            "mean        0.101679\n",
            "std         0.302226\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "max         1.000000\n",
            "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
            "количество дубликатов в таблице = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pl1xPaXsrnEJ"
      },
      "source": [
        "comments_new = []\n",
        "for sentence in comments.text:\n",
        " \n",
        "   comments_new.append(\" \". join(sentence.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBEm77hStzDt"
      },
      "source": [
        "comments[\"text_split\"]=comments_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80EdjnLk3NL1"
      },
      "source": [
        "## Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3cPQsRb0xHD"
      },
      "source": [
        "Для дальнейшего использования 159571 очень большой датасет, поэтому сделаем sample.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY8VxlEkdQdR"
      },
      "source": [
        "переменную **corpus** будем использовать для TF-IDF,  \n",
        "**corpus_b** для модели BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHH3Yv8B1GjE"
      },
      "source": [
        "sample_size = 30000\n",
        "sample_size_b = 5000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apFLwEzqBlGk"
      },
      "source": [
        "corpus = comments.sample(n=sample_size,random_state=0).reset_index()\n",
        "corpus_b = comments.sample(n=sample_size_b,random_state=0).reset_index()\n",
        " \n",
        "corpus = corpus.drop('index',axis=1)\n",
        "corpus_b = corpus_b.drop('index',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1_srbzUkg6O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WRiuQcXeM-4",
        "outputId": "d4562e26-75f4-4380-f71b-fd439a733d66"
      },
      "source": [
        " \n",
        "print('соотношение классов в датасете corpus\\n', corpus.toxic.value_counts()/corpus.shape[0]*100)\n",
        " \n",
        "print('соотношение классов в датасете corpus_b\\n',corpus_b.toxic.value_counts()/corpus_b.shape[0]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "соотношение классов в датасете corpus\n",
            " 0    89.646667\n",
            "1    10.353333\n",
            "Name: toxic, dtype: float64\n",
            "соотношение классов в датасете corpus_b\n",
            " 0    90.1\n",
            "1     9.9\n",
            "Name: toxic, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4jaNZbp1kE_"
      },
      "source": [
        "Соотношение классов приблизтельно как в исходном датасете.  \n",
        "Можно считать, что baseline по accuracy для данного датасета около  89,7 - 90.1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU8oTASdB4Ka"
      },
      "source": [
        "# TF-IDF модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN-oByHjB4K4"
      },
      "source": [
        "Будем применять Wordnet Lemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "ynoyWjtqB4K5",
        "outputId": "41753c4f-0b7b-43b5-96bf-eefbbab1b51b"
      },
      "source": [
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>text_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
              "      <td>0</td>\n",
              "      <td>\" I haven't paraphrased you at all, Gary. You ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "      <td>1</td>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "      <td>0</td>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "      <td>0</td>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                         text_split\n",
              "0  \"\\nI haven't paraphrased you at all, Gary.  Yo...  ...  \" I haven't paraphrased you at all, Gary. You ...\n",
              "1  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...  ...  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...\n",
              "2  I'm sorry. I'd like to unreservedly retract my...  ...  I'm sorry. I'd like to unreservedly retract my...\n",
              "3  I don't know if this is exactly like the Press...  ...  I don't know if this is exactly like the Press...\n",
              "4  Thank you all, we'll all improve the Wikipedia...  ...  Thank you all, we'll all improve the Wikipedia...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl89-KI1B4K7"
      },
      "source": [
        "# инициализация Wordnet Lemmatizer\n",
        "L = WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M__ucVTB4K8"
      },
      "source": [
        "def lemmatizered(corpus):\n",
        "  ''' функция выполняет токенизациию и лемматизацию массива текстов'''\n",
        "  corpus_new = []\n",
        "  for sentence in corpus:\n",
        "    word_list = nltk.word_tokenize(sentence)\n",
        "    corpus_new.append(' '.join([L.lemmatize(w) for w in word_list]))\n",
        "  return corpus_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSBBbJ3-B4K9"
      },
      "source": [
        "def get_wordnet_pos(word):\n",
        "    \"\"\"функция возвращает словарь, где возвращается значение часть речи (pos_tag)\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        " \n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slxaw6p5B4K-"
      },
      "source": [
        "def get_word_text(corpus):\n",
        "  ''' функция выполняет токенизациию и лемматизацию массива текстов c учетом pos_tag'''\n",
        "  corpus_new = []\n",
        "  for sentence in corpus:\n",
        "    corpus_new.append(' '.join([L.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)]))\n",
        "  return corpus_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itMZWX4IB4K-"
      },
      "source": [
        "приведем все слова к нижнему регистру"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "t6uNaJrmB4K_",
        "outputId": "835b52a8-b3de-4bbf-e6d5-9c7dbbcd58ea"
      },
      "source": [
        "corpus['text_split'] = corpus['text_split'].str.lower()\n",
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>text_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
              "      <td>0</td>\n",
              "      <td>\" i haven't paraphrased you at all, gary. you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "      <td>1</td>\n",
              "      <td>i blocked revers! i blocked revers! i blocked ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "      <td>1</td>\n",
              "      <td>i'm sorry. i'd like to unreservedly retract my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "      <td>0</td>\n",
              "      <td>i don't know if this is exactly like the press...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "      <td>0</td>\n",
              "      <td>thank you all, we'll all improve the wikipedia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                         text_split\n",
              "0  \"\\nI haven't paraphrased you at all, Gary.  Yo...  ...  \" i haven't paraphrased you at all, gary. you ...\n",
              "1  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...  ...  i blocked revers! i blocked revers! i blocked ...\n",
              "2  I'm sorry. I'd like to unreservedly retract my...  ...  i'm sorry. i'd like to unreservedly retract my...\n",
              "3  I don't know if this is exactly like the Press...  ...  i don't know if this is exactly like the press...\n",
              "4  Thank you all, we'll all improve the Wikipedia...  ...  thank you all, we'll all improve the wikipedia...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hqgOIZtB4LB"
      },
      "source": [
        "Выполним лемматизацию корпуса c учетом pos_tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "l6EiVRv7B4LB",
        "outputId": "fb30bc54-9064-444c-bff7-83e19e07d584"
      },
      "source": [
        " \n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        " \n",
        "corpus['lemma_text'] = get_word_text(corpus['text_split'])\n",
        "corpus.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>text_split</th>\n",
              "      <th>lemma_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
              "      <td>0</td>\n",
              "      <td>\" i haven't paraphrased you at all, gary. you ...</td>\n",
              "      <td>`` i have n't paraphrase you at all , gary . y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "      <td>1</td>\n",
              "      <td>i blocked revers! i blocked revers! i blocked ...</td>\n",
              "      <td>i block revers ! i block revers ! i block reve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "      <td>1</td>\n",
              "      <td>i'm sorry. i'd like to unreservedly retract my...</td>\n",
              "      <td>i 'm sorry . i 'd like to unreservedly retract...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "      <td>0</td>\n",
              "      <td>i don't know if this is exactly like the press...</td>\n",
              "      <td>i do n't know if this be exactly like the pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "      <td>0</td>\n",
              "      <td>thank you all, we'll all improve the wikipedia...</td>\n",
              "      <td>thank you all , we 'll all improve the wikiped...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                         lemma_text\n",
              "0  \"\\nI haven't paraphrased you at all, Gary.  Yo...  ...  `` i have n't paraphrase you at all , gary . y...\n",
              "1  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...  ...  i block revers ! i block revers ! i block reve...\n",
              "2  I'm sorry. I'd like to unreservedly retract my...  ...  i 'm sorry . i 'd like to unreservedly retract...\n",
              "3  I don't know if this is exactly like the Press...  ...  i do n't know if this be exactly like the pres...\n",
              "4  Thank you all, we'll all improve the Wikipedia...  ...  thank you all , we 'll all improve the wikiped...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s55pI5Xxfqez"
      },
      "source": [
        "Создадим переменную stopwords и передадим в нее список стоп слов английского языка из библ.nltk"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G-_a7bxB4LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698ecf94-4040-4364-9499-8d9c74a45e01"
      },
      "source": [
        " \n",
        " \n",
        "nltk.download('stopwords')\n",
        "stopwords = set(nltk_stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QG_WPg6eB4LC"
      },
      "source": [
        "разделим наши данные на train_corpus ,test_corpus.  \n",
        "test_corpus в дальнейшем будем использовать для тестирования модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta3LavqGB4LC"
      },
      "source": [
        "train_corpus,test_corpus = train_test_split(corpus, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dULvNU-B4LE"
      },
      "source": [
        "выполним векторизацию слов методом TfidfVectorizer, при этом удалим из текста стоп-слова.   \n",
        "Метод fit настривает модель, transform выполняет вектризацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AikuwnxkB4LE"
      },
      "source": [
        "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
        "tf_idf = count_tf_idf.fit(train_corpus['lemma_text'])\n",
        "tf_idf_train = tf_idf.transform(train_corpus['lemma_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTPwpKZkB4LF"
      },
      "source": [
        "test_tf_idf = tf_idf.transform(test_corpus['lemma_text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L6W4HsxB4LF",
        "outputId": "2c3f0d1c-5475-4674-c578-d551ac0bca82"
      },
      "source": [
        "print(\"Размер матрицы train:\", tf_idf_train.shape)\n",
        "print(\"Размер матрицы test:\", test_tf_idf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер матрицы train: (15000, 40216)\n",
            "Размер матрицы test: (15000, 40216)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ykjU_SQmtTT",
        "outputId": "3bc5f426-4697-4381-839e-9bcde142220b"
      },
      "source": [
        "tf_idf_train.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCUY98gLB4LG"
      },
      "source": [
        "Обозначим что есть признаки и таргеты для трейн и тест."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-t5P_6HxB4LG"
      },
      "source": [
        "X_train = tf_idf_train\n",
        "X_test = test_tf_idf\n",
        "y_train = train_corpus['toxic'].values\n",
        "y_test = test_corpus['toxic'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-zQU_V-B4LH",
        "outputId": "bb106d55-0598-4c19-dc93-22401b7fa608"
      },
      "source": [
        "print(X_train.shape,X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15000, 40216) (15000, 40216)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gCys2rMgSUv"
      },
      "source": [
        "Создадим скоринг для кросс-валидации.  \n",
        "По заданию нужно добиться значения F-меры более 0.75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf13XN6UB4LI"
      },
      "source": [
        "f1 = make_scorer(f1_score , average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frdjRSO-B4LI"
      },
      "source": [
        "def treshold(array,tresh_list,y_test):\n",
        "  ''' функция настраивает порог классификации для метода predict_proba'''\n",
        "  best_result = 0\n",
        "  #best_predict = []\n",
        "  for i in tresh_list:\n",
        "    tmp_list = np.empty([len(array),2])\n",
        "    for j,k in enumerate(array[:,1]):\n",
        "      if k<i:\n",
        "        tmp_list[j,1] = 0\n",
        "      else:\n",
        "        tmp_list[j,1] = 1\n",
        "    result = f1_score(y_test,tmp_list[:,1])\n",
        "    #print(result,i)   \n",
        "    if result>best_result:\n",
        "      best_result=result\n",
        "      best_tresh = i\n",
        "      #best_predict = tmp_list\n",
        "  return best_result,best_tresh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "4FYq_JpkpJTw",
        "outputId": "a5e80b35-6889-44dd-b03d-0ec210ffd7f0"
      },
      "source": [
        "result_df = pd.DataFrame(columns=['F1_predict','F1_predict_proba','Treshold'])\n",
        "result_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_predict</th>\n",
              "      <th>F1_predict_proba</th>\n",
              "      <th>Treshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [F1_predict, F1_predict_proba, Treshold]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVTWwNx-g7QV"
      },
      "source": [
        "### Логистическая классификация для TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcJ9xmw-B4LJ",
        "outputId": "109e7819-77c7-428f-d9bd-617945b4940e"
      },
      "source": [
        " parameters = {'C': np.linspace(0.0001, 5000, 50),'max_iter':[100,200],'class_weight':['balanced', None]}\n",
        " grid_search = GridSearchCV(LogisticRegression(random_state=0), parameters,scoring=f1,n_jobs=-1,cv=5)\n",
        " grid_search.fit(X_train, y_train)\n",
        " \n",
        " print('best parameters: ', grid_search.best_params_)\n",
        " print('best scrores: ', grid_search.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 102.04091428571428, 'class_weight': 'balanced', 'max_iter': 100}\n",
            "best scrores:  0.8492330207759704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7-kqch9B4LJ",
        "outputId": "d25fe843-31f1-48e8-d056-62b55516f3b1"
      },
      "source": [
        "lr_clf_TF_IDF = LogisticRegression(**grid_search.best_params_,random_state = 0)\n",
        "lr_clf_TF_IDF.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=102.04091428571428, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8-GYG4-B4LK",
        "outputId": "070f51a7-ba06-46a1-f6a1-c3caf0f163a8"
      },
      "source": [
        "f1_lr_clf_train = f1_score(lr_clf_TF_IDF.predict(X_train),y_train)\n",
        "f1_lr_clf_test = f1_score(lr_clf_TF_IDF.predict(X_test),y_test)\n",
        "print('f1_score для TF_IDF на тренировочной выборке =', f1_lr_clf_train)\n",
        "print('f1_score для TF_IDF на тестовой выборке =',f1_lr_clf_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score для TF_IDF на тренировочной выборке = 0.9974009096816114\n",
            "f1_score для TF_IDF на тестовой выборке = 0.7331975560081466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Z_s0ifCHPx5"
      },
      "source": [
        "подберем порог классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OThVG_4QB4LK"
      },
      "source": [
        "TF_IDF_predict_proba = lr_clf_TF_IDF.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5x5h3gXB4LM",
        "outputId": "497e8ca5-342c-4233-f68a-d901b85a11bb"
      },
      "source": [
        "lr_clf_TF_IDF_result,lr_clf_TF_IDF_tresh = treshold(TF_IDF_predict_proba,np.linspace(0.1,0.9,50),y_test)\n",
        "print('лучшее значение f1 и порог равны',lr_clf_TF_IDF_result,lr_clf_TF_IDF_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "лучшее значение f1 и порог равны 0.7331738981892724 0.5244897959183674\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2FKYkSJr9OQ"
      },
      "source": [
        "def result_write(model_name,f1,f1_p,t):\n",
        "  result_df.loc[model_name,'F1_predict'] = f1\n",
        "  result_df.loc[model_name,'F1_predict_proba'] = f1_p\n",
        "  result_df.loc[model_name,'Treshold'] = t\n",
        "  return result_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "id": "PsQrhGLgs5hl",
        "outputId": "538b6ab8-bbce-4907-f52e-3513589136f1"
      },
      "source": [
        "result_write('Log reg TF-IDF',f1_lr_clf_test,lr_clf_TF_IDF_result,lr_clf_TF_IDF_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_predict</th>\n",
              "      <th>F1_predict_proba</th>\n",
              "      <th>Treshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log reg TF-IDF</th>\n",
              "      <td>0.733198</td>\n",
              "      <td>0.733174</td>\n",
              "      <td>0.52449</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               F1_predict F1_predict_proba Treshold\n",
              "Log reg TF-IDF   0.733198         0.733174  0.52449"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aLJHDGgh_vV"
      },
      "source": [
        "## Random Forest для TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBBbUDWUB4LQ",
        "outputId": "57d5d10d-4156-4c06-9eae-3da1b3a53b06"
      },
      "source": [
        "parameters = {'n_estimators': [500,1000]} #'max_depth' : [280,300,320]\n",
        "grid_rfc = GridSearchCV(RandomForestClassifier(random_state=0), parameters,scoring=f1,n_jobs=-1,cv=3)\n",
        "grid_rfc.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=0,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'n_estimators': [500, 1000]}, pre_dispatch='2*n_jobs',\n",
              "             refit=True, return_train_score=False,\n",
              "             scoring=make_scorer(f1_score, average=macro), verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ffEHXkFB4LQ",
        "outputId": "5dd1db01-c6f3-47d3-b165-753bd30e9dde"
      },
      "source": [
        "print('best parameters: ', grid_rfc.best_params_)\n",
        "print('best scrores: ', grid_rfc.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'n_estimators': 500}\n",
            "best scrores:  0.813438432225964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIXJ10XYB4LU",
        "outputId": "c728052d-6a5f-4fd8-a6d4-cb59c9b7aaaf"
      },
      "source": [
        "rfc = RandomForestClassifier(**grid_rfc.best_params_)\n",
        "rfc.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx032lq8B4LV",
        "outputId": "532b3f9b-40d9-46de-a57a-cff0c377878f"
      },
      "source": [
        "f1_rfc_train = f1_score(rfc.predict(X_train),y_train)\n",
        "f1_rfc_test = f1_score(rfc.predict(X_test),y_test)\n",
        "print('f1_score для TF_IDF на тренировочной выборке =', f1_rfc_train)\n",
        "print('f1_score для TF_IDF на тестовой выборке =',f1_rfc_test)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score для TF_IDF на тренировочной выборке = 0.9993489583333334\n",
            "f1_score для TF_IDF на тестовой выборке = 0.6803874092009685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwEdHmK0B4LV",
        "outputId": "1275e597-2e09-44bf-8b0f-b2b215cc6735"
      },
      "source": [
        "rfc_predict_proba = rfc.predict_proba(X_test)\n",
        "rfc_TF_IDF_result,rfc_TF_IDF_tresh = treshold(rfc_predict_proba,np.linspace(0.1,0.9,50),y_test)\n",
        "print('лучшее значение f1 и порог равны',rfc_TF_IDF_result,rfc_TF_IDF_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "лучшее значение f1 и порог равны 0.7605829285218599 0.3122448979591837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsoOKyUHB4LW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "958de6f8-9fbd-480c-82d6-76c4381d9434"
      },
      "source": [
        "result_write('Random_forest TF-IDF',f1_rfc_test,rfc_TF_IDF_result,rfc_TF_IDF_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_predict</th>\n",
              "      <th>F1_predict_proba</th>\n",
              "      <th>Treshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log reg TF-IDF</th>\n",
              "      <td>0.733198</td>\n",
              "      <td>0.733174</td>\n",
              "      <td>0.52449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_forest TF-IDF</th>\n",
              "      <td>0.680387</td>\n",
              "      <td>0.760583</td>\n",
              "      <td>0.312245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     F1_predict F1_predict_proba  Treshold\n",
              "Log reg TF-IDF         0.733198         0.733174   0.52449\n",
              "Random_forest TF-IDF   0.680387         0.760583  0.312245"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fx5a3J7SMy0"
      },
      "source": [
        "Получили необходимое значение F1 для RandomForest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnNZKfNAjG7n"
      },
      "source": [
        "## DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcfn73-9B4LW",
        "outputId": "2bd9942e-bf5b-4e43-c757-c8573ef46dc7"
      },
      "source": [
        "\n",
        "clf = DummyClassifier(random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "Dummy_predict = clf.predict(X_test)\n",
        "Dummy_predict_proba = clf.predict_proba(X_test)\n",
        "dummy_TF_IDF_result,dummy_TF_IDF_tresh = treshold(Dummy_predict_proba,np.linspace(0.001,0.9,50),y_test)\n",
        "\n",
        "print(\"Dummy classifier score: \" ,f1_score(y_test,Dummy_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dummy classifier score:  0.10894941634241244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcwLIpw_BlP_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "outputId": "37703f62-6f18-4815-82da-8e6d88f270e2"
      },
      "source": [
        "result_write('DummyClassifier',f1_score(y_test,Dummy_predict),dummy_TF_IDF_result,dummy_TF_IDF_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_predict</th>\n",
              "      <th>F1_predict_proba</th>\n",
              "      <th>Treshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log reg TF-IDF</th>\n",
              "      <td>0.733198</td>\n",
              "      <td>0.733174</td>\n",
              "      <td>0.52449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_forest TF-IDF</th>\n",
              "      <td>0.680387</td>\n",
              "      <td>0.760583</td>\n",
              "      <td>0.312245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.108949</td>\n",
              "      <td>0.108949</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     F1_predict F1_predict_proba  Treshold\n",
              "Log reg TF-IDF         0.733198         0.733174   0.52449\n",
              "Random_forest TF-IDF   0.680387         0.760583  0.312245\n",
              "DummyClassifier        0.108949         0.108949     0.001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qkTcjdUBlVq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yyxVMA5BlZ6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXdGfbVEBlfW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05x_vaf7Bli4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzDGBHOdjNfC"
      },
      "source": [
        "#BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaB7utu61qWB"
      },
      "source": [
        "Для дальнейшей работы изменим размер(длину) текстов до 512 символов.. Это необходимо, чтобы корректно(без ошибок) выполнить токенизацию. И далее когда будем использовать BERT модель , то получим ошибку по максимальной длине токенов = 512.  \n",
        " \n",
        "Описание предтренированных данных сказано:\n",
        "12-layer, 768-hidden, 12-heads, 110M parameters.\n",
        "Trained on **uncased English**, т.е. к нижнему регистру приводить не надо."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38zwZX27bD7r",
        "outputId": "e0318c0f-e407-4b34-e940-4c37f1bc3946"
      },
      "source": [
        "for k,i in enumerate(corpus_b['text_split']):\n",
        "  longest = 0\n",
        "  if len(corpus_b['text_split'][k])>longest:\n",
        "    longest = len(corpus_b['text_split'][k])\n",
        "print(longest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc1ToX70Ui3d"
      },
      "source": [
        "corpus_b['text_512'] = np.zeros(corpus_b.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XwQP5cE3H7G"
      },
      "source": [
        "for k,i in enumerate(corpus_b['text_split']):\n",
        "    corpus_b['text_512'][k]=i[:512]\n",
        "    #comments['text_512'][k]=i[-512:] Попробовал взять последние 512 слов, результат тот же."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "eVAnxpcf00GN",
        "outputId": "cfd91ddc-1aec-4953-ebcf-8f91e2b41f7d"
      },
      "source": [
        "corpus_b.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_512</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"\\nI haven't paraphrased you at all, Gary.  Yo...</td>\n",
              "      <td>0</td>\n",
              "      <td>\" I haven't paraphrased you at all, Gary. You ...</td>\n",
              "      <td>\" I haven't paraphrased you at all, Gary. You ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "      <td>1</td>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "      <td>I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "      <td>1</td>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "      <td>I'm sorry. I'd like to unreservedly retract my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "      <td>0</td>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "      <td>I don't know if this is exactly like the Press...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "      <td>0</td>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "      <td>Thank you all, we'll all improve the Wikipedia...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                           text_512\n",
              "0  \"\\nI haven't paraphrased you at all, Gary.  Yo...  ...  \" I haven't paraphrased you at all, Gary. You ...\n",
              "1  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...  ...  I BLOCKED REVERS! I BLOCKED REVERS! I BLOCKED ...\n",
              "2  I'm sorry. I'd like to unreservedly retract my...  ...  I'm sorry. I'd like to unreservedly retract my...\n",
              "3  I don't know if this is exactly like the Press...  ...  I don't know if this is exactly like the Press...\n",
              "4  Thank you all, we'll all improve the Wikipedia...  ...  Thank you all, we'll all improve the Wikipedia...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_MO08_KiAOb"
      },
      "source": [
        "## Загружаем предтренированную модель BERT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLR1NqnDV8n6"
      },
      "source": [
        "Перебпровал различные предтренированные модели.  \n",
        "Лучшие показатели у 'bert-base-uncased'.  \n",
        "Модель принимает значение в обоих регистрах!  \n",
        "Обучена на BookCorpus, 11 038 неопубликлванных книг и English Wikipedia (исключая списки, таблицы,заголовки)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe1BYuDxv49Y"
      },
      "source": [
        "configuration = ppb.BertConfig(max_position_embeddings=2048)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvyiVLJn30la"
      },
      "source": [
        "## BERT:\n",
        "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel(configuration), ppb.BertTokenizer, 'bert-base-uncased') \n",
        "# results:\n",
        "# bert-base-uncased 0.66 \n",
        "# bert-large-uncased 0.59\n",
        "# bert-base-uncased-finetuned-mrpc 0.66\n",
        "# bert-base-multilingual-uncased 0.45\n",
        "# bert-large-cased-whole-word-masking-finetuned-squad 0.59\n",
        " \n",
        " \n",
        "# Загружаем предтренированную model/tokenizer BERT\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model_tokenizer_class = model_class.from_pretrained(pretrained_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbzTYxYJ3_2f"
      },
      "source": [
        " \n",
        "### Токенизация.\n",
        " \n",
        "Токенизируем каждый текст , т.е. приводим в формат для BERT моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urzle3c47J8s"
      },
      "source": [
        "tokenized= corpus_b['text_512'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHwjUwYgi-uL"
      },
      "source": [
        "Принцип токенизации.  \n",
        "Взято с блока Jay Alammar.\n",
        "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
        "\n",
        "### Padding (заполнение)\n",
        "После токенизации, каждый токенизированный текст имеет разную длину.\n",
        "Для дальнейшей работы BERT модели необходимо привести все \"тексты\" к одной размерности.  \n",
        "Для этого добавим 0 до размера самого большого текста. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URn-DWJt5xhP",
        "outputId": "2898539e-67ca-418c-c302-e57cfaaa060a"
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        " \n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YHKuBBC_zoN",
        "outputId": "9f29d4ba-e45c-4511-d7a6-a497992d0390"
      },
      "source": [
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "print(padded.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 357)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mdjg306wjjmL"
      },
      "source": [
        "Размерность датасета 5000 строк на 357 столбцов.  \n",
        "Все строки одной длины."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDZBsYSDjzDV"
      },
      "source": [
        "### Masking (маскирование)  \n",
        "Если подать данные в таком виде в BERT модель, то модель не сработает, дело в добавленных 0. Необходимо создать еще одную переменную, чтобы она маскировала добавленные 0(padding). Поэтому создадим  attention_mask:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K_iGRNa_Ozc",
        "outputId": "c8fa2083-ac70-4976-847a-b790e1f9a8c5"
      },
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "print(attention_mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 357)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367,
          "referenced_widgets": [
            "999dc20a1b164bc3b6cd78cbe6600d5a",
            "529140cbd8ca4ab1966662a87795fece",
            "fd2bcd56a0b7425ca32c91b1c7217520",
            "09660d177d6646f79c247b5bd593dc70",
            "dba392717624413daa92643cb3beb98f",
            "6097c0bdd0894b738b1df0b0085cddec",
            "429c4ee4e0df4c729fe1aaa0c1b19c51",
            "71516623cf6a40358e896ded7c44485b"
          ]
        },
        "id": "mHLetII3gT6l",
        "outputId": "c43fee9d-0b4b-415b-ad76-b5785e761d57"
      },
      "source": [
        "batch_size = 1000\n",
        "embeddings = []\n",
        "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
        "        batch = torch.IntTensor(padded[batch_size*i:batch_size*(i+1)])\n",
        "        attention_mask_batch = torch.IntTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
        "        with torch.no_grad():\n",
        "            batch_embeddings = model_tokenizer_class(batch, attention_mask=attention_mask_batch)\n",
        "        \n",
        "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
        " \n",
        "embeddings[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "999dc20a1b164bc3b6cd78cbe6600d5a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ 0.17508629,  0.06400632, -0.19117032, ..., -0.1570864 ,\n",
              "          0.49064207,  0.41450417],\n",
              "        [-0.29137355, -0.10913293,  0.20857978, ...,  0.02302492,\n",
              "          0.2964966 ,  0.68998164],\n",
              "        [ 0.01597106, -0.15524422, -0.37359148, ..., -0.02488263,\n",
              "          0.17746924,  0.57595164],\n",
              "        ...,\n",
              "        [-0.07746883, -0.31962118, -0.0884318 , ..., -0.54371226,\n",
              "          0.5737397 ,  0.7110472 ],\n",
              "        [ 0.17904532,  0.07629653,  0.09958477, ..., -0.02940109,\n",
              "          0.41762403,  0.40146947],\n",
              "        [-0.0606179 ,  0.05414834, -0.00974915, ..., -0.04243546,\n",
              "          0.20950316,  0.50788856]], dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF5ySGooDTnF"
      },
      "source": [
        "Созадим признаки для обучения моделей классификации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pltMq8pGUqJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92725a55-840a-4975-fd81-e600e09faad5"
      },
      "source": [
        "features = np.concatenate(embeddings)\n",
        "print(features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD3fX2yh6PTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b54e86-9788-444a-bd3e-ec7ac3668d03"
      },
      "source": [
        "labels = corpus_b['toxic']\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75oyhr3VxHoE"
      },
      "source": [
        "## Логистическая классификация для BERT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeQ52UAsilLi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(features, labels,test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGcb--7qD6Ze"
      },
      "source": [
        "Выполним подбор коэфф.регуляризации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP6ZDD4OilMD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fc49be-7fe7-42c2-8a6d-8e3ea3eb76b4"
      },
      "source": [
        " parameters = {'C': np.linspace(0.0001, 5000, 50),'class_weight':['balanced']}\n",
        " grid_search_bert = GridSearchCV(LogisticRegression(random_state=0), parameters,scoring=f1,n_jobs=-1,cv=5)\n",
        " grid_search_bert.fit(X_train, y_train)\n",
        " \n",
        " print('best parameters: ', grid_search_bert.best_params_)\n",
        " print('best scores: ', grid_search_bert.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 918.3674285714285, 'class_weight': 'balanced'}\n",
            "best scores:  0.7984095314425541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmn5HjMeilME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc008c82-7178-4488-c377-e9d04be25dc7"
      },
      "source": [
        "lr_clf_BERT = LogisticRegression(**grid_search_bert.best_params_,random_state=0)\n",
        "lr_clf_BERT.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=918.3674285714285, class_weight='balanced', dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaIH6HFANJLs"
      },
      "source": [
        "BERT_predict_train = lr_clf_BERT.predict(X_train)\n",
        "BERT_predict = lr_clf_BERT.predict(X_test)\n",
        "BERT_predict_proba = lr_clf_BERT.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMqDsL1rilMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3374027-80d5-4e83-d3d7-b5f8a56f0d49"
      },
      "source": [
        "f1_lr_clf_train_bert = f1_score(BERT_predict_train,y_train)\n",
        "f1_lr_clf_test_bert = f1_score(BERT_predict,y_test)\n",
        "print('f1_score для BERT на тренировочной выборке =', f1_lr_clf_train_bert)\n",
        "print('f1_score для BERT на тестовой выборке =',f1_lr_clf_test_bert)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score для BERT на тренировочной выборке = 1.0\n",
            "f1_score для BERT на тестовой выборке = 0.5646123260437375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5M8LtglMX42m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19a1ec8-ef5a-48c4-b292-cbf691492c87"
      },
      "source": [
        "lr_clf_BERT_result,lr_clf_BERT_tresh = treshold(BERT_predict_proba,np.linspace(0.1,0.9,50),y_test)\n",
        "print('лучшее значение f1 и порог равны',lr_clf_BERT_result,lr_clf_BERT_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "лучшее значение f1 и порог равны 0.5767634854771786 0.753061224489796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgTvAkdW7XUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "83bf849f-64fb-454f-f757-6702bf2d58b9"
      },
      "source": [
        "result_write('Log reg BERT',f1_lr_clf_test_bert,lr_clf_BERT_result,lr_clf_BERT_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_predict</th>\n",
              "      <th>F1_predict_proba</th>\n",
              "      <th>Treshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log reg TF-IDF</th>\n",
              "      <td>0.733198</td>\n",
              "      <td>0.733174</td>\n",
              "      <td>0.52449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_forest TF-IDF</th>\n",
              "      <td>0.680387</td>\n",
              "      <td>0.760583</td>\n",
              "      <td>0.312245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.108949</td>\n",
              "      <td>0.108949</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Log reg BERT</th>\n",
              "      <td>0.564612</td>\n",
              "      <td>0.576763</td>\n",
              "      <td>0.753061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     F1_predict F1_predict_proba  Treshold\n",
              "Log reg TF-IDF         0.733198         0.733174   0.52449\n",
              "Random_forest TF-IDF   0.680387         0.760583  0.312245\n",
              "DummyClassifier        0.108949         0.108949     0.001\n",
              "Log reg BERT           0.564612         0.576763  0.753061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiu194R3ZGI8"
      },
      "source": [
        "## Random Forest для BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ouq8hJn3cpVd"
      },
      "source": [
        " Подберем гиперпараметры для случайного леса."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WGC9njLZGI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "410e4de7-67d1-4b5e-b89d-85ad093ca101"
      },
      "source": [
        "parameters = {'n_estimators': [80,100],'max_depth' : [3,5,10], 'class_weight' : ['balanced']}\n",
        "grid_rfc_BERT = GridSearchCV(RandomForestClassifier(random_state=0), parameters,scoring=f1,n_jobs=-1,cv=5)\n",
        "grid_rfc_BERT.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=0,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'class_weight': ['balanced'], 'max_depth': [3, 5, 10],\n",
              "                         'n_estimators': [80, 100]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=make_scorer(f1_score, average=macro), verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FT7QPW_HZGJA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab68cc87-d6d2-4822-b512-29df91a04bca"
      },
      "source": [
        "print('best parameters: ', grid_rfc_BERT.best_params_)\n",
        "print('best scrores: ', grid_rfc_BERT.best_score_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best parameters:  {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 80}\n",
            "best scrores:  0.7970155790010286\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxF7m71UZGJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351b96d4-95db-4cb3-de2a-d5584a6b84c8"
      },
      "source": [
        "rfc_Bert = RandomForestClassifier(**grid_rfc_BERT.best_params_)\n",
        "rfc_Bert.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',\n",
              "                       criterion='gini', max_depth=5, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=80,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFoqdom3ZGJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d507bf-2b9a-4399-b0b0-d6b84fef009e"
      },
      "source": [
        "f1_rfc_Bert_train = f1_score(rfc_Bert.predict(X_train),y_train)\n",
        "f1_rfc_Bert_test = f1_score(rfc_Bert.predict(X_test),y_test)\n",
        "print('f1_score для BERT на тренировочной выборке =', f1_rfc_Bert_train)\n",
        "print('f1_score для BERT на тестовой выборке =',f1_rfc_Bert_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score для BERT на тренировочной выборке = 0.897887323943662\n",
            "f1_score для BERT на тестовой выборке = 0.5972222222222221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op9E2pniZGJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41445334-f261-4989-fcb3-837b84ce84ef"
      },
      "source": [
        "rfc_BERT_predict_proba = rfc_Bert.predict_proba(X_test)\n",
        "rfc_BERT_result,rfc_BERT_tresh = treshold(rfc_BERT_predict_proba,np.linspace(0.1,0.9,50),y_test)\n",
        "print('лучшее значение f1 и порог равны',rfc_BERT_result,rfc_BERT_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "лучшее значение f1 и порог равны 0.6096491228070176 0.4755102040816327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZz2lr6KZGJF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "5d388237-338f-48b8-caec-8a9ea35085e9"
      },
      "source": [
        "result_write('Random_forest BERT',f1_rfc_Bert_test,rfc_BERT_result,rfc_BERT_tresh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1_predict</th>\n",
              "      <th>F1_predict_proba</th>\n",
              "      <th>Treshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Log reg TF-IDF</th>\n",
              "      <td>0.733198</td>\n",
              "      <td>0.733174</td>\n",
              "      <td>0.52449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_forest TF-IDF</th>\n",
              "      <td>0.680387</td>\n",
              "      <td>0.760583</td>\n",
              "      <td>0.312245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.108949</td>\n",
              "      <td>0.108949</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Log reg BERT</th>\n",
              "      <td>0.564612</td>\n",
              "      <td>0.576763</td>\n",
              "      <td>0.753061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random_forest BERT</th>\n",
              "      <td>0.597222</td>\n",
              "      <td>0.609649</td>\n",
              "      <td>0.47551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     F1_predict F1_predict_proba  Treshold\n",
              "Log reg TF-IDF         0.733198         0.733174   0.52449\n",
              "Random_forest TF-IDF   0.680387         0.760583  0.312245\n",
              "DummyClassifier        0.108949         0.108949     0.001\n",
              "Log reg BERT           0.564612         0.576763  0.753061\n",
              "Random_forest BERT     0.597222         0.609649   0.47551"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muTPzcEAblPF"
      },
      "source": [
        "# Вывод:\n",
        "1. выполнено создание  признаков для текстов моделью BERT и TF_IDF;\n",
        "2. Далее с помощью логистической регрессии и случ.леса выполнены настройки моделей, с подбором гиперпараметров;\n",
        "3. Единственная модель которая выдала необходимый результат это TF_IDF + Random_Forest;\n",
        "4. Для построения признаков TF-IDF использовал 30000 строк, для BERT - 5000 строк;\n",
        "5. Если увеличить выборку , то результаты улучшатся незначительно + это занимает очень много времени;\n",
        "5. Т.к. при постоении признаков для BERT моделли есть ограничение в 512 слов, то пришлось сделать ограничение. Считаю , из-за этого не удалось показать хорошие результаты для BERT.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aMC3HduStwQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4uiAgvZQZ4v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhzLU4z1QaI4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7bODkj5HkZu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}